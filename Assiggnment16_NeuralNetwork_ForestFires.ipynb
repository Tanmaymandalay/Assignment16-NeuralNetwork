{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assiggnment16_NeuralNetwork_ForestFires.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tKQXxikWN0u"
      },
      "source": [
        "# Create your first MLP in Keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIvSbBgYWfEw"
      },
      "source": [
        "dataset=pd.read_csv('/content/forestfires.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "y0U-QsJQWjDm",
        "outputId": "4160a4d0-1000-4448-de92-28974c8cb297"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "on2-FE1OcpLq",
        "outputId": "a47c44f5-819c-4c3b-aa61-b990c4c1bcd8"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.644681</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>12.847292</td>\n",
              "      <td>0.164410</td>\n",
              "      <td>0.143133</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.117988</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.355899</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.038685</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.332689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.520111</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>63.655818</td>\n",
              "      <td>0.371006</td>\n",
              "      <td>0.350548</td>\n",
              "      <td>0.369244</td>\n",
              "      <td>0.387657</td>\n",
              "      <td>0.322907</td>\n",
              "      <td>0.329662</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.193029</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.241199</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.043980</td>\n",
              "      <td>0.168007</td>\n",
              "      <td>0.471632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.200000</td>\n",
              "      <td>68.600000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>92.900000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.570000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             FFMC         DMC          DC  ...    monthnov    monthoct    monthsep\n",
              "count  517.000000  517.000000  517.000000  ...  517.000000  517.000000  517.000000\n",
              "mean    90.644681  110.872340  547.940039  ...    0.001934    0.029014    0.332689\n",
              "std      5.520111   64.046482  248.066192  ...    0.043980    0.168007    0.471632\n",
              "min     18.700000    1.100000    7.900000  ...    0.000000    0.000000    0.000000\n",
              "25%     90.200000   68.600000  437.700000  ...    0.000000    0.000000    0.000000\n",
              "50%     91.600000  108.300000  664.200000  ...    0.000000    0.000000    0.000000\n",
              "75%     92.900000  142.400000  713.900000  ...    0.000000    0.000000    1.000000\n",
              "max     96.200000  291.300000  860.600000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-llly6_pct9b",
        "outputId": "09a18de8-e504-43a7-d2ad-2034b4220934"
      },
      "source": [
        "dataset.isna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.isna of     month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNrlopcdfOf_"
      },
      "source": [
        "#Dummy variables are already created, so we will remove the month and alsoday columns\n",
        "dataset.drop([\"month\",\"day\"],axis=1,inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_func(i):\n",
        "    x = (i-i.min())/(i.max()-i.min())\n",
        "    return (x)"
      ],
      "metadata": {
        "id": "15TlF6wYwnU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gy73_ObXYcV"
      },
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:28]\n",
        "Y = dataset.iloc[:,28]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wkBj0Yvgze3"
      },
      "source": [
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qCfYFzahzCy",
        "outputId": "02cb3dd7-6e9d-49eb-b908-a6d62d7cdbbd"
      },
      "source": [
        "pd.DataFrame(X_standardized).describe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of            0         1         2   ...         25        26        27\n",
              "0   -0.805959 -1.323326 -1.830477  ...  -0.044023 -0.172860 -0.706081\n",
              "1   -0.008102 -1.179541  0.488891  ...  -0.044023  5.785038 -0.706081\n",
              "2   -0.008102 -1.049822  0.560715  ...  -0.044023  5.785038 -0.706081\n",
              "3    0.191362 -1.212361 -1.898266  ...  -0.044023 -0.172860 -0.706081\n",
              "4   -0.243833 -0.931043 -1.798600  ...  -0.044023 -0.172860 -0.706081\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "512 -1.640083 -0.846648  0.474768  ...  -0.044023 -0.172860 -0.706081\n",
              "513 -1.640083 -0.846648  0.474768  ...  -0.044023 -0.172860 -0.706081\n",
              "514 -1.640083 -0.846648  0.474768  ...  -0.044023 -0.172860 -0.706081\n",
              "515  0.680957  0.549003  0.269382  ...  -0.044023 -0.172860 -0.706081\n",
              "516 -2.020879 -1.685913 -1.780442  ...  22.715633 -0.172860 -0.706081\n",
              "\n",
              "[517 rows x 28 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f85ysqQYj5U-"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGBFLfY-iSos"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV , KFold\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#import tensorflow as tf\n",
        "#optim = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "UlLPS0XqyQng",
        "outputId": "baf6fc3b-37d3-4080-f4be-1150c6320361"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder_x=LabelEncoder()\n",
        "X=X.apply(LabelEncoder().fit_transform)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>41</td>\n",
              "      <td>29</td>\n",
              "      <td>12</td>\n",
              "      <td>34</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>42</td>\n",
              "      <td>85</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>156</td>\n",
              "      <td>42</td>\n",
              "      <td>55</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67</td>\n",
              "      <td>48</td>\n",
              "      <td>33</td>\n",
              "      <td>64</td>\n",
              "      <td>13</td>\n",
              "      <td>72</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>66</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>30</td>\n",
              "      <td>73</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>9</td>\n",
              "      <td>71</td>\n",
              "      <td>141</td>\n",
              "      <td>7</td>\n",
              "      <td>172</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>9</td>\n",
              "      <td>71</td>\n",
              "      <td>141</td>\n",
              "      <td>7</td>\n",
              "      <td>123</td>\n",
              "      <td>54</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>9</td>\n",
              "      <td>71</td>\n",
              "      <td>141</td>\n",
              "      <td>7</td>\n",
              "      <td>116</td>\n",
              "      <td>53</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>92</td>\n",
              "      <td>168</td>\n",
              "      <td>122</td>\n",
              "      <td>80</td>\n",
              "      <td>156</td>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     FFMC  DMC   DC  ISI  ...  monthmay  monthnov  monthoct  monthsep\n",
              "0      28   37   41   29  ...         0         0         0         0\n",
              "1      56   49  144   42  ...         0         0         1         0\n",
              "2      56   56  156   42  ...         0         0         1         0\n",
              "3      67   48   33   64  ...         0         0         0         0\n",
              "4      46   66   46   68  ...         0         0         0         0\n",
              "..    ...  ...  ...  ...  ...       ...       ...       ...       ...\n",
              "512     9   71  141    7  ...         0         0         0         0\n",
              "513     9   71  141    7  ...         0         0         0         0\n",
              "514     9   71  141    7  ...         0         0         0         0\n",
              "515    92  168  122   80  ...         0         0         0         0\n",
              "516     7    2   48    4  ...         0         1         0         0\n",
              "\n",
              "[517 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NnYh91-zTzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24b0ac0-db8c-41fb-cf41-6b59fa2406ff"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      small\n",
              "1      small\n",
              "2      small\n",
              "3      small\n",
              "4      small\n",
              "       ...  \n",
              "512    large\n",
              "513    large\n",
              "514    large\n",
              "515    small\n",
              "516    small\n",
              "Name: size_category, Length: 517, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iVHQwXQ4zDtm",
        "outputId": "94c46037-60e9-45cd-8cfb-0751f0ecad52"
      },
      "source": [
        "Y = pd.DataFrame(Y)\n",
        "label_encoder_y = LabelEncoder()\n",
        "Y = Y.apply(LabelEncoder().fit_transform)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     size_category\n",
              "0                1\n",
              "1                1\n",
              "2                1\n",
              "3                1\n",
              "4                1\n",
              "..             ...\n",
              "512              0\n",
              "513              0\n",
              "514              0\n",
              "515              1\n",
              "516              1\n",
              "\n",
              "[517 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = norm_func(X)"
      ],
      "metadata": {
        "id": "-MNS1cHrwZ6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp9Hi6x-YuAQ"
      },
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=28, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "    adam= Adam(lr=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3qt2F2BpkxP",
        "outputId": "c71f6e3d-9ea3-4e43-d50c-eb59924cadbf"
      },
      "source": [
        "model = KerasClassifier(build_fn= create_model, verbose=0)\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size = batch_size, epochs = epochs)\n",
        "grid = GridSearchCV(estimator = model, param_grid= param_grid, cv = KFold(), verbose = 10)\n",
        "grid_result = grid.fit(X_standardized, Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.971 total time=   5.6s\n",
            "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.856 total time=   3.2s\n",
            "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.854 total time=   1.3s\n",
            "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.845 total time=   1.3s\n",
            "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.874 total time=   1.4s\n",
            "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   3.1s\n",
            "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.875 total time=   3.2s\n",
            "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.825 total time=   3.3s\n",
            "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.922 total time=   3.2s\n",
            "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.922 total time=   3.2s\n",
            "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   5.3s\n",
            "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.856 total time=   5.4s\n",
            "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.893 total time=   5.4s\n",
            "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.913 total time=   5.8s\n",
            "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.913 total time=   5.7s\n",
            "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   0.9s\n",
            "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.808 total time=   1.0s\n",
            "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.738 total time=   1.0s\n",
            "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.825 total time=   1.0s\n",
            "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.864 total time=   1.0s\n",
            "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   2.6s\n",
            "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.837 total time=   1.9s\n",
            "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.893 total time=   1.9s\n",
            "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.903 total time=   1.9s\n",
            "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.893 total time=   2.3s\n",
            "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   3.1s\n",
            "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.865 total time=   3.1s\n",
            "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.903 total time=   3.2s\n",
            "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.903 total time=   3.3s\n",
            "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.893 total time=   3.1s\n",
            "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   0.8s\n",
            "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.750 total time=   0.8s\n",
            "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.699 total time=   0.8s\n",
            "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9663e22c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.718 total time=   0.8s\n",
            "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9664898200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.835 total time=   1.2s\n",
            "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.990 total time=   2.0s\n",
            "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.875 total time=   1.9s\n",
            "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.883 total time=   1.4s\n",
            "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.903 total time=   1.9s\n",
            "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.893 total time=   1.4s\n",
            "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   2.1s\n",
            "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.856 total time=   2.0s\n",
            "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.883 total time=   2.0s\n",
            "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.903 total time=   3.2s\n",
            "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.883 total time=   2.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrMVpe1Avp_A",
        "outputId": "fef64ae6-91ac-4891-ccb1-f0032d04c2fc"
      },
      "source": [
        "print('Best: {}, Using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
        "means=grid_result.cv_results_['mean_test_score']\n",
        "stds=grid_result.cv_results_['std_test_score']\n",
        "params=grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print ('{},{} with {}'.format(mean, stdev, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.9148431658744812, Using {'batch_size': 10, 'epochs': 100}\n",
            "0.8799477219581604,0.046563082679960455 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.9089805722236634,0.057978730345665544 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.9148431658744812,0.04736992780462155 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.8469753503799439,0.086752256837151 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.9051717519760132,0.052904619429510275 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.9128827452659607,0.04567614673390516 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.8004854440689086,0.11006043282387298 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.908999252319336,0.041752918622437026 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n",
            "0.9051344275474549,0.049755107845870124 with [{'batch_size': 10, 'epochs': 10}, {'batch_size': 10, 'epochs': 50}, {'batch_size': 10, 'epochs': 100}, {'batch_size': 20, 'epochs': 10}, {'batch_size': 20, 'epochs': 50}, {'batch_size': 20, 'epochs': 100}, {'batch_size': 40, 'epochs': 10}, {'batch_size': 40, 'epochs': 50}, {'batch_size': 40, 'epochs': 100}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test= train_test_split(X_norm,Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "MPoIikTGu3BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model=create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KyTh2U0wvYM",
        "outputId": "5bb07fef-6d6f-42e4-a171-a3970f2881ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844834GCfZc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb11ddf-6598-4d22-ace8-60d49a15e22e"
      },
      "source": [
        "# Fit the model\n",
        "final_model.fit(x_train, y_train, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 0.0942 - val_accuracy: 0.9562\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 0.1126 - val_accuracy: 0.9635\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.3122 - val_accuracy: 0.9270\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9746 - val_loss: 0.3550 - val_accuracy: 0.9197\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 0.1230 - val_accuracy: 0.9489\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9746 - val_loss: 0.0918 - val_accuracy: 0.9635\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9783 - val_loss: 0.2504 - val_accuracy: 0.9416\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 0.1842 - val_accuracy: 0.9343\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.1502 - val_accuracy: 0.9416\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 0.1447 - val_accuracy: 0.9416\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.1555 - val_accuracy: 0.9343\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9562\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9416\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9416\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9416\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9964 - val_loss: 0.1348 - val_accuracy: 0.9416\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9416\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9416\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9343\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9416\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9416\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9343\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.8450e-04 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9416\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.3672e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9343\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.4567e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9416\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.2075e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9343\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.9388e-04 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9416\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.7279e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9343\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.9309e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9416\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 6.4001e-04 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9343\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 6.1785e-04 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9343\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 6.2164e-04 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9343\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 5.5925e-04 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9343\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 5.5664e-04 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9343\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 5.4119e-04 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9343\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 5.0570e-04 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9343\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 4.5111e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9343\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 4.2917e-04 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9343\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 4.2918e-04 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9416\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 4.1254e-04 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9343\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 4.2821e-04 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9343\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.5118e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9416\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.6676e-04 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9343\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.5815e-04 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9416\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.3041e-04 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9343\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.2245e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9416\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.1225e-04 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9416\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.8305e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9416\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.0359e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9416\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 3.0690e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9416\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.8441e-04 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9343\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.6497e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9416\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2.4771e-04 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9416\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.5259e-04 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9416\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.3780e-04 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9416\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.3443e-04 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9416\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.3340e-04 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9416\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.2648e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9416\n",
            "Epoch 59/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.1607e-04 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9416\n",
            "Epoch 60/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.0758e-04 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9343\n",
            "Epoch 61/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.9827e-04 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9416\n",
            "Epoch 62/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.0190e-04 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9416\n",
            "Epoch 63/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.0138e-04 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9416\n",
            "Epoch 64/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.8759e-04 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9416\n",
            "Epoch 65/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.1138e-04 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9343\n",
            "Epoch 66/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.1315e-04 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9416\n",
            "Epoch 67/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.6417e-04 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9416\n",
            "Epoch 68/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.5985e-04 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9416\n",
            "Epoch 69/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.5574e-04 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9416\n",
            "Epoch 70/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.5480e-04 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9416\n",
            "Epoch 71/100\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.5548e-04 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9416\n",
            "Epoch 72/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.4532e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9416\n",
            "Epoch 73/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.6007e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9416\n",
            "Epoch 74/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.7045e-04 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9343\n",
            "Epoch 75/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.4958e-04 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9416\n",
            "Epoch 76/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.2726e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9416\n",
            "Epoch 77/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.2488e-04 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9416\n",
            "Epoch 78/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.2823e-04 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9416\n",
            "Epoch 79/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.1408e-04 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9416\n",
            "Epoch 80/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.2111e-04 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9416\n",
            "Epoch 81/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.1663e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9416\n",
            "Epoch 82/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0566e-04 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9416\n",
            "Epoch 83/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0820e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9416\n",
            "Epoch 84/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0556e-04 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9416\n",
            "Epoch 85/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0464e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9416\n",
            "Epoch 86/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0380e-04 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9416\n",
            "Epoch 87/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.6559e-05 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9416\n",
            "Epoch 88/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 9.2948e-05 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9416\n",
            "Epoch 89/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0163e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9416\n",
            "Epoch 90/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0644e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9416\n",
            "Epoch 91/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8515e-05 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9416\n",
            "Epoch 92/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.5654e-05 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9416\n",
            "Epoch 93/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.2786e-05 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9416\n",
            "Epoch 94/100\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.5012e-05 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9416\n",
            "Epoch 95/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.0020e-05 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9416\n",
            "Epoch 96/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.1435e-05 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9416\n",
            "Epoch 97/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.7659e-05 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9416\n",
            "Epoch 98/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.7990e-05 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9416\n",
            "Epoch 99/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.2959e-05 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9416\n",
            "Epoch 100/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 7.4227e-05 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9663be7550>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP1cKWe_fboV",
        "outputId": "f091e91e-9409-46c7-8360-ede1b58cd197"
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = final_model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy))\n",
        "print('Loss: %f' % (loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.980630\n",
            "Loss: 0.058044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = final_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy))\n",
        "print('Loss: %f' % (loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUC2Gy7Iw-Mj",
        "outputId": "0f8c8a37-0e5f-465e-8f3d-b1079206dd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.932692\n",
            "Loss: 0.373422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = final_model.fit(x_train, y_train,\n",
        "   batch_size = 128, epochs = 10,\n",
        "   verbose = 2, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNMcvpWByywj",
        "outputId": "deb8568e-c55a-433a-f227-c002b0191087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 - 0s - loss: 0.0650 - accuracy: 0.9806 - val_loss: 0.2473 - val_accuracy: 0.9615 - 189ms/epoch - 47ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.2342 - val_accuracy: 0.9519 - 55ms/epoch - 14ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 0.0270 - accuracy: 0.9855 - val_loss: 0.1295 - val_accuracy: 0.9519 - 47ms/epoch - 12ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 0.0122 - accuracy: 0.9927 - val_loss: 0.0702 - val_accuracy: 0.9808 - 48ms/epoch - 12ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 0.0129 - accuracy: 0.9927 - val_loss: 0.0963 - val_accuracy: 0.9712 - 47ms/epoch - 12ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.1157 - val_accuracy: 0.9615 - 51ms/epoch - 13ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0975 - val_accuracy: 0.9808 - 63ms/epoch - 16ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1071 - val_accuracy: 0.9615 - 51ms/epoch - 13ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.1312 - val_accuracy: 0.9615 - 49ms/epoch - 12ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.1286 - val_accuracy: 0.9615 - 43ms/epoch - 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__a1lMGzgzY",
        "outputId": "ce4342cf-b5ae-45b8-a89e-405cb05b2e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "lmTTVAiKzpdP",
        "outputId": "fe0831b3-bc12-46a9-aa0e-0bf565549162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2bxjyPU2_Lh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}